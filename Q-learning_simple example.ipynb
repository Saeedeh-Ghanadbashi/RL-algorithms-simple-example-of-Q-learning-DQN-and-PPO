{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03f5c0b-4210-446d-8704-00cca83f4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "\n",
    "GRID_SIZE = 3\n",
    "START = (0, 0)\n",
    "GOAL = (2, 2)\n",
    "OBSTACLE = (1, 1)\n",
    "\n",
    "ACTIONS = [\n",
    "    (-1, 0), #up\n",
    "    (0, 1),  #right\n",
    "    (1, 0),  #down\n",
    "    (0, -1)  #left\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896be500-17a5-493c-af46-b276915fac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_state (state: Tuple[int, int]) -> bool:\n",
    "    return (0<= state[0] < GRID_SIZE and\n",
    "            0<= state[1] < GRID_SIZE and\n",
    "            state != OBSTACLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411c1b8d-2476-4195-bd47-6065586770af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(state: Tuple[int, int], action: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    next_state = (state[0] + action[0] , state[1] + action[1])\n",
    "    return next_state if is_valid_state(next_state) else state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d323d2b-6d71-401a-865a-8ee0ebfccdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.3\n",
    "ALPHA = 0.3\n",
    "GAMA = 0.99\n",
    "EPISODES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2126b3e1-1d9d-4507-91cf-4960c9180a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state: Tuple[int, int], next_state: Tuple[int, int]) -> int:\n",
    "    if next_state == GOAL:\n",
    "        return 100\n",
    "    elif next_state == OBSTACLE or next_state == state:\n",
    "        return -10\n",
    "    else:\n",
    "        return -1 # small penalty for each step, encourage the shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8768cac4-690f-4b6f-96c8-0872e6dbd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state: Tuple[int, int], q_table: np.ndarray) -> Tuple[int, int]:\n",
    "    if random.uniform(0, 1)<EPSILON:\n",
    "        return random.choice(ACTIONS)\n",
    "    else:\n",
    "        return ACTIONS[np.argmax(q_table[state])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4499cdc1-e589-47db-aa72-3c6bf6fda022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(q_table: np.ndarray, state: Tuple[int, int], action: Tuple[int, int], reward: int, next_state: Tuple[int, int]) -> None:\n",
    "    action_idx = ACTIONS.index(action)\n",
    "    q_table[state][action_idx] += ALPHA * (reward + GAMA * np.max(q_table[next_state]) - q_table[state][action_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22b804b1-2a14-4e46-8d43-e0244bc61caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent() -> np.ndarray:\n",
    "    q_table = np.zeros((GRID_SIZE, GRID_SIZE, len(ACTIONS)))\n",
    "\n",
    "    for _ in range(EPISODES):\n",
    "        state = START\n",
    "        while state != GOAL:\n",
    "            action = choose_action(state, q_table)\n",
    "            next_state = get_next_state(state, action)\n",
    "            reward = get_reward(state, next_state)\n",
    "            update_q_table(q_table, state, action, reward, next_state)\n",
    "            state = next_state\n",
    "    return q_table\n",
    "\n",
    "q_table = train_agent()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b54ba6-a08a-4baa-895f-89884e70722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_q_table_as_grid(q_table: np.ndarray) -> None:\n",
    "    \"\"\"Visualize the Q-table as a grid with all action values for each state.\"\"\"\n",
    "    action_symbols = ['^', '>', 'v', '<']\n",
    "    \n",
    "    print(\"\\nDetailed Q-table Grid:\")\n",
    "    \n",
    "    # Header\n",
    "    header = \"   |\" + \"|\".join(f\"   ({i},{j})   \" for i in range(GRID_SIZE) for j in range(GRID_SIZE)) + \"|\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for action_idx, action_symbol in enumerate(action_symbols):\n",
    "        row = f\" {action_symbol} |\"\n",
    "        for i in range(GRID_SIZE):\n",
    "            for j in range(GRID_SIZE):\n",
    "                if (i, j) == GOAL:\n",
    "                    cell = \"   GOAL    \"\n",
    "                elif (i, j) == OBSTACLE:\n",
    "                    cell = \" OBSTACLE  \"\n",
    "                else:\n",
    "                    q_value = q_table[i, j, action_idx]\n",
    "                    cell = f\" {q_value:9.2f} \"\n",
    "                row += cell + \"|\"\n",
    "        print(row)\n",
    "        print(\"-\" * len(header))\n",
    "\n",
    "def visualize_best_actions_grid(q_table: np.ndarray) -> None:\n",
    "    \"\"\"Visualize the best action and its Q-value for each state in a grid.\"\"\"\n",
    "    action_symbols = ['^', '>', 'v', '<']\n",
    "    \n",
    "    print(\"\\nBest Actions Grid:\")\n",
    "    header = \"-\" * (14 * GRID_SIZE + 1)\n",
    "    print(header)\n",
    "\n",
    "    for i in range(GRID_SIZE):\n",
    "        row = \"| \"\n",
    "        for j in range(GRID_SIZE):\n",
    "            if (i, j) == GOAL:\n",
    "                cell = \"   GOAL    \"\n",
    "            elif (i, j) == OBSTACLE:\n",
    "                cell = \" OBSTACLE  \"\n",
    "            else:\n",
    "                best_action_idx = np.argmax(q_table[i, j])\n",
    "                best_q_value = q_table[i, j, best_action_idx]\n",
    "                cell = f\"{action_symbols[best_action_idx]}:{best_q_value:7.2f}  \"\n",
    "            row += cell + \" | \"\n",
    "        print(row)\n",
    "        print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09936e6d-ee96-45ba-8e49-82d67787991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Q-table Grid:\n",
      "   |   (0,0)   |   (0,1)   |   (0,2)   |   (1,0)   |   (1,1)   |   (1,2)   |   (2,0)   |   (2,1)   |   (2,2)   |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      " ^ |     83.12 |     85.06 |     87.02 |     92.12 | OBSTACLE  |     96.02 |     94.06 |     89.00 |   GOAL    |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      " > |     94.06 |     96.02 |     87.02 |     85.06 | OBSTACLE  |     89.00 |     98.00 |    100.00 |   GOAL    |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      " v |     94.06 |     85.06 |     98.00 |     96.02 | OBSTACLE  |    100.00 |     87.02 |     89.00 |   GOAL    |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      " < |     83.12 |     92.12 |     94.06 |     85.06 | OBSTACLE  |     89.00 |     87.02 |     96.02 |   GOAL    |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Actions Grid:\n",
      "-------------------------------------------\n",
      "| >:  94.06   | >:  96.02   | v:  98.00   | \n",
      "-------------------------------------------\n",
      "| v:  96.02   |  OBSTACLE   | v: 100.00   | \n",
      "-------------------------------------------\n",
      "| >:  98.00   | >: 100.00   |    GOAL     | \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Visualize the Q-table as a grid\n",
    "visualize_q_table_as_grid(q_table)\n",
    "\n",
    "# Visualize the best actions and their Q-values in a grid\n",
    "visualize_best_actions_grid(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bde8cd-cfd0-40de-95e9-1d9ff1fac9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
